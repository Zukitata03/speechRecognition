{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1c8242026f470ba21530d9199bc0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696f0f2cc5ba4df8b7a10ccae2aec1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='pause', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb73616b9704e99abda9a1ccad3b233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Analyze', icon='stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52633e24a217460898118828a18cb360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from IPython.display import display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "messages = Queue() #tell the thread when to stop recording\n",
    "recordings = Queue() #store the recordings\n",
    "\n",
    "\n",
    "transcriptions = []\n",
    "transcribe = None\n",
    "\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "record_button = widgets.Button(\n",
    "    description='Record',\n",
    "    disabled=False,\n",
    "    button_style = 'success',\n",
    "    icon = 'microphone'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style = 'warning',\n",
    "    icon = 'pause'\n",
    ")\n",
    "\n",
    "\n",
    "def start_recording(data):\n",
    "    messages.put(True)\n",
    "    \n",
    "    with output:\n",
    "        display(\"Recording...\")\n",
    "        record = Thread(target=record_microphone)\n",
    "        record.start()\n",
    "        \n",
    "        transcribe = Thread(target=speech_recognition, args=(output,))\n",
    "        transcribe.start()\n",
    "        \n",
    "        \n",
    "def stop_recording(data):\n",
    "    global transcriptions, transcribe\n",
    "    with output:\n",
    "        messages.get()\n",
    "        display(\"Stopped recording\")\n",
    "        \n",
    "        # Wait for the transcription thread to finish\n",
    "        if transcribe is not None:\n",
    "            transcribe.join()\n",
    "            \n",
    "\n",
    "def analyze_sentiment(data):\n",
    "    # Create a DataFrame from all transcriptions and save to CSV\n",
    "    if transcriptions:  # Make sure the list is not empty\n",
    "        df = pd.DataFrame(transcriptions, columns=['TEXT'])\n",
    "        df['Negative'], df['Neutral'], df['Positive'], df['Emotion'], df['Subjectivity'], df['Opinion/Fact?'], df['Weighted Sentiment'] = zip(*df['TEXT'].map(getSentiment))\n",
    "        df.to_csv('all_transcriptions.csv', index=False)\n",
    "        \n",
    "        # Style DataFrame\n",
    "        styled = df.style.set_table_styles([\n",
    "            {\"selector\": \"th\", \"props\": [(\"background-color\", \"white\")]},\n",
    "            {\"selector\": \"td\", \"props\": [(\"background-color\", \"white\")]}\n",
    "        ])\n",
    "\n",
    "        display(styled)\n",
    "    else:\n",
    "        display(\"No transcriptions to analyze\")\n",
    "        \n",
    "\n",
    "analyze_button = widgets.Button(\n",
    "    description=\"Analyze\",\n",
    "    disabled=False,\n",
    "    button_style = 'danger',\n",
    "    icon = 'stop'\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "#Click xong th√¨ n√≥ s·∫Ω g·ªçi h√†m start_recording v√† stop_recording\n",
    "record_button.on_click(start_recording) \n",
    "stop_button.on_click(stop_recording)    \n",
    "analyze_button.on_click(analyze_sentiment)\n",
    "\n",
    "output = widgets.Output()\n",
    "display(record_button, stop_button, analyze_button, output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329b315c896544e1a5344ad522325cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e060250269ac48ea89aba66d11f1205f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='pause', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f32f460af254623a17c76376e4e1a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Analyze', icon='stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9afb54749004c7b8af8bc6f01cdbbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2aa75 th {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_2aa75 td {\n",
       "  background-color: white;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2aa75\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2aa75_level0_col0\" class=\"col_heading level0 col0\" >TEXT</th>\n",
       "      <th id=\"T_2aa75_level0_col1\" class=\"col_heading level0 col1\" >Negative</th>\n",
       "      <th id=\"T_2aa75_level0_col2\" class=\"col_heading level0 col2\" >Neutral</th>\n",
       "      <th id=\"T_2aa75_level0_col3\" class=\"col_heading level0 col3\" >Positive</th>\n",
       "      <th id=\"T_2aa75_level0_col4\" class=\"col_heading level0 col4\" >Emotion</th>\n",
       "      <th id=\"T_2aa75_level0_col5\" class=\"col_heading level0 col5\" >Subjectivity</th>\n",
       "      <th id=\"T_2aa75_level0_col6\" class=\"col_heading level0 col6\" >Opinion/Fact?</th>\n",
       "      <th id=\"T_2aa75_level0_col7\" class=\"col_heading level0 col7\" >Weighted Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2aa75_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2aa75_row0_col0\" class=\"data row0 col0\" >i had three house</td>\n",
       "      <td id=\"T_2aa75_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_2aa75_row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "      <td id=\"T_2aa75_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_2aa75_row0_col4\" class=\"data row0 col4\" >Neutral üòê</td>\n",
       "      <td id=\"T_2aa75_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "      <td id=\"T_2aa75_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_2aa75_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea33272dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from IPython.display import display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "messages = Queue() #tell the thread when to stop recording\n",
    "recordings = Queue() #store the recordings\n",
    "\n",
    "\n",
    "transcriptions = []\n",
    "transcribe = None\n",
    "\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "record_button = widgets.Button(\n",
    "    description='Record',\n",
    "    disabled=False,\n",
    "    button_style = 'success',\n",
    "    icon = 'microphone'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style = 'warning',\n",
    "    icon = 'pause'\n",
    ")\n",
    "\n",
    "\n",
    "def start_recording(data):\n",
    "    messages.put(True)\n",
    "    \n",
    "    with output:\n",
    "        display(\"Recording...\")\n",
    "        record = Thread(target=record_microphone)\n",
    "        record.start()\n",
    "        \n",
    "        transcribe = Thread(target=speech_recognition, args=(output,))\n",
    "        transcribe.start()\n",
    "        \n",
    "        \n",
    "def stop_recording(data):\n",
    "    global transcriptions, transcribe\n",
    "    with output:\n",
    "        messages.get()\n",
    "        display(\"Stopped recording\")\n",
    "        \n",
    "        # Wait for the transcription thread to finish\n",
    "        if transcribe is not None:\n",
    "            transcribe.join()\n",
    "            \n",
    "\n",
    "def analyze_sentiment(data):\n",
    "    # Create a DataFrame from all transcriptions and save to CSV\n",
    "    if transcriptions:  # Make sure the list is not empty\n",
    "        df = pd.DataFrame(transcriptions, columns=['TEXT'])\n",
    "        df['Negative'], df['Neutral'], df['Positive'], df['Emotion'], df['Subjectivity'], df['Opinion/Fact?'], df['Weighted Sentiment'] = zip(*df['TEXT'].map(getSentiment))\n",
    "        df.to_csv('all_transcriptions.csv', index=False)\n",
    "        \n",
    "        # Style DataFrame\n",
    "        styled = df.style.set_table_styles([\n",
    "            {\"selector\": \"th\", \"props\": [(\"background-color\", \"white\")]},\n",
    "            {\"selector\": \"td\", \"props\": [(\"background-color\", \"white\")]}\n",
    "        ])\n",
    "\n",
    "        display(styled)\n",
    "    else:\n",
    "        display(\"No transcriptions to analyze\")\n",
    "        \n",
    "\n",
    "analyze_button = widgets.Button(\n",
    "    description=\"Analyze\",\n",
    "    disabled=False,\n",
    "    button_style = 'danger',\n",
    "    icon = 'stop'\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "#Click xong th√¨ n√≥ s·∫Ω g·ªçi h√†m start_recording v√† stop_recording\n",
    "record_button.on_click(start_recording) \n",
    "stop_button.on_click(stop_recording)    \n",
    "analyze_button.on_click(analyze_sentiment)\n",
    "\n",
    "output = widgets.Output()\n",
    "display(record_button, stop_button, analyze_button, output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone Array (4- Realtek(R)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'FxSound Speakers (FxSound Audio', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'Speakers (4- Realtek(R) Audio)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Primary Sound Capture Driver', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': 'Microphone Array (4- Realtek(R) Audio)', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'Primary Sound Driver', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': 'FxSound Speakers (FxSound Audio Enhancer)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 9, 'structVersion': 2, 'name': 'Speakers (4- Realtek(R) Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 10, 'structVersion': 2, 'name': 'Speakers (4- Realtek(R) Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 11, 'structVersion': 2, 'name': 'FxSound Speakers (FxSound Audio Enhancer)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 12, 'structVersion': 2, 'name': 'Microphone Array (4- Realtek(R) Audio)', 'hostApi': 2, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 13, 'structVersion': 2, 'name': 'Speakers (Realtek HD Audio output)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 14, 'structVersion': 2, 'name': 'Stereo Mix (Realtek HD Audio Stereo input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 15, 'structVersion': 2, 'name': 'Microphone Array (Realtek HD Audio Mic input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 16, 'structVersion': 2, 'name': 'Headphones (Realtek HD Audio 2nd output)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 17, 'structVersion': 2, 'name': 'Mic in at front panel (black) (Mic in at front panel (black))', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 18, 'structVersion': 2, 'name': 'Input ()', 'hostApi': 3, 'maxInputChannels': 8, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n",
      "{'index': 19, 'structVersion': 2, 'name': 'Speakers ()', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))\n",
    "    \n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 1\n",
    "FRAME_RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "AUDIO_FORMAT = pyaudio.paInt16\n",
    "SAMPLE_SIZE = 2\n",
    "\n",
    "def record_microphone(chunk = 1024):\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=FRAME_RATE, input=True,input_device_index=1, frames_per_buffer=chunk)\n",
    "    frames = []\n",
    "    \n",
    "    while not messages.empty():\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "        \n",
    "        #every record_seconds seconds, put the frames into the queue, then start recording another record_seconds audio \n",
    "        if len(frames) >= (FRAME_RATE * RECORD_SECONDS/chunk):\n",
    "            recordings.put(frames.copy())\n",
    "            frames = []\n",
    "            \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "model = Model(r'E:\\Homework\\AI\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15')\n",
    "rec = KaldiRecognizer(model, FRAME_RATE)\n",
    "rec.SetWords(True)\n",
    "\n",
    "def speech_recognition(output):\n",
    "    global transcriptions  # Declare transcriptions as global\n",
    "    while not messages.empty():\n",
    "        frames = recordings.get()\n",
    "        \n",
    "        rec.AcceptWaveform(b''.join(frames))\n",
    "        result = rec.Result()\n",
    "        text = json.loads(result)['text']\n",
    "        output.append_stdout(text)\n",
    "        transcriptions.append(text)  # Save transcription\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getSentiment(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    blob = TextBlob(text)\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "    opinion_fact = int(subjectivity > 0.5) \n",
    "    # Assuming subjectivity score > 0.5 indicates an opinion\n",
    "    if opinion_fact == 1:\n",
    "        opinion_fact_text = 'Opinion'\n",
    "    else:\n",
    "        opinion_fact = 'Fact'\n",
    "    weighted_sentiment_text = sentiment['compound'] * subjectivity\n",
    "    return sentiment['neg'], sentiment['neu'], sentiment['pos'], getSentimentLabel(sentiment), subjectivity, opinion_fact_text, weighted_sentiment\n",
    "\n",
    "def getSentimentLabel(sentiment):\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return 'Positive üòÉ'\n",
    "    elif sentiment['compound'] <= -0.05:\n",
    "        return 'Negative üòû'\n",
    "    else:\n",
    "        return 'Neutral üòê'\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone Array (4- Realtek(R)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'FxSound Speakers (FxSound Audio', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'Speakers (4- Realtek(R) Audio)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Primary Sound Capture Driver', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': 'Microphone Array (4- Realtek(R) Audio)', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'Primary Sound Driver', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': 'FxSound Speakers (FxSound Audio Enhancer)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 9, 'structVersion': 2, 'name': 'Speakers (4- Realtek(R) Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 10, 'structVersion': 2, 'name': 'Speakers (4- Realtek(R) Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 11, 'structVersion': 2, 'name': 'FxSound Speakers (FxSound Audio Enhancer)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 12, 'structVersion': 2, 'name': 'Microphone Array (4- Realtek(R) Audio)', 'hostApi': 2, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 13, 'structVersion': 2, 'name': 'Speakers (Realtek HD Audio output)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 14, 'structVersion': 2, 'name': 'Stereo Mix (Realtek HD Audio Stereo input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 15, 'structVersion': 2, 'name': 'Microphone Array (Realtek HD Audio Mic input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 16, 'structVersion': 2, 'name': 'Headphones (Realtek HD Audio 2nd output)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 17, 'structVersion': 2, 'name': 'Mic in at front panel (black) (Mic in at front panel (black))', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 18, 'structVersion': 2, 'name': 'Input ()', 'hostApi': 3, 'maxInputChannels': 8, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n",
      "{'index': 19, 'structVersion': 2, 'name': 'Speakers ()', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))\n",
    "    \n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 1\n",
    "FRAME_RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "AUDIO_FORMAT = pyaudio.paInt16\n",
    "SAMPLE_SIZE = 2\n",
    "\n",
    "def record_microphone(chunk = 1024):\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=FRAME_RATE, input=True,input_device_index=1, frames_per_buffer=chunk)\n",
    "    frames = []\n",
    "    \n",
    "    while not messages.empty():\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "        \n",
    "        #every record_seconds seconds, put the frames into the queue, then start recording another record_seconds audio \n",
    "        if len(frames) >= (FRAME_RATE * RECORD_SECONDS/chunk):\n",
    "            recordings.put(frames.copy())\n",
    "            frames = []\n",
    "            \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "model = Model(r'E:\\Homework\\AI\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15')\n",
    "rec = KaldiRecognizer(model, FRAME_RATE)\n",
    "rec.SetWords(True)\n",
    "\n",
    "def speech_recognition(output):\n",
    "    global transcriptions  # Declare transcriptions as global\n",
    "    while not messages.empty():\n",
    "        frames = recordings.get()\n",
    "        \n",
    "        rec.AcceptWaveform(b''.join(frames))\n",
    "        result = rec.Result()\n",
    "        text = json.loads(result)['text']\n",
    "        output.append_stdout(text)\n",
    "        transcriptions.append(text)  # Save transcription\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getSentiment(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    blob = TextBlob(text)\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    opinion_fact = int(subjectivity > 0.5)  # Assuming subjectivity score > 0.5 indicates an opinion\n",
    "    if opinion_fact == 1:\n",
    "        opinion_fact = 'Opinion'\n",
    "    else:\n",
    "        opinion_fact = 'Fact'\n",
    "    weighted_sentiment = sentiment['compound'] * subjectivity\n",
    "    return sentiment['neg'], sentiment['neu'], sentiment['pos'], getSentimentLabel(sentiment), subjectivity, opinion_fact, weighted_sentiment\n",
    "\n",
    "def getSentimentLabel(sentiment):\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return 'Positive üòÉ'\n",
    "    elif sentiment['compound'] <= -0.05:\n",
    "        return 'Negative üòû'\n",
    "    else:\n",
    "        return 'Neutral üòê'\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
